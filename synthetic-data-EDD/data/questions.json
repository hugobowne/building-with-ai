[
  {
    "id": "synth_student_cohort_student_1",
    "question": "What are some common metrics or criteria I should use to evaluate the quality of responses generated by my LLM applications?",
    "user_type": "student",
    "scenario": "cohort_student"
  },
  {
    "id": "synth_student_cohort_student_2",
    "question": "Can you explain how prompt engineering can significantly impact the outputs of an LLM and provide some examples of effective prompts?",
    "user_type": "student",
    "scenario": "cohort_student"
  },
  {
    "id": "synth_student_general_1",
    "question": "What are the key differences between RAG and traditional retrieval methods when building LLM applications?",
    "user_type": "student",
    "scenario": "general"
  },
  {
    "id": "synth_student_general_2",
    "question": "Can you explain how prompt engineering works and why it is important for developing effective LLM-powered applications?",
    "user_type": "student",
    "scenario": "general"
  },
  {
    "id": "synth_student_technical_1",
    "question": "What are some best practices for prompt engineering to ensure I get the most relevant outputs from LLMs in my applications?",
    "user_type": "student",
    "scenario": "technical"
  },
  {
    "id": "synth_student_technical_2",
    "question": "How can I effectively evaluate the performance of my LLM application and determine if it's meeting the desired criteria for reliability?",
    "user_type": "student",
    "scenario": "technical"
  },
  {
    "id": "synth_student_factual_1",
    "question": "What are the key differences between retrieval-augmented generation (RAG) and traditional generative models in LLM applications?",
    "user_type": "student",
    "scenario": "factual"
  },
  {
    "id": "synth_student_factual_2",
    "question": "Can you explain how to evaluate the performance of an LLM application and what metrics are commonly used for this purpose?",
    "user_type": "student",
    "scenario": "factual"
  },
  {
    "id": "synth_data_scientist_cohort_student_1",
    "question": "What are some best practices for using prompt engineering effectively to optimize the responses of LLMs in my data analysis projects?",
    "user_type": "data_scientist",
    "scenario": "cohort_student"
  },
  {
    "id": "synth_data_scientist_cohort_student_2",
    "question": "How can I evaluate the reliability and performance of my LLM applications using synthetic data and the tools discussed in the workshop?",
    "user_type": "data_scientist",
    "scenario": "cohort_student"
  },
  {
    "id": "synth_data_scientist_general_1",
    "question": "What are the key considerations for integrating LLMs into existing data analysis workflows to ensure reliability and accuracy?",
    "user_type": "data_scientist",
    "scenario": "general"
  },
  {
    "id": "synth_data_scientist_general_2",
    "question": "Can you clarify the role of synthetic data in training LLMs and how it impacts the overall performance of the application?",
    "user_type": "data_scientist",
    "scenario": "general"
  },
  {
    "id": "synth_data_scientist_technical_1",
    "question": "What are the best practices for using synthetic data in training LLMs to ensure that the models generalize well to real-world scenarios?",
    "user_type": "data_scientist",
    "scenario": "technical"
  },
  {
    "id": "synth_data_scientist_technical_2",
    "question": "Can you explain how observability in LLM applications can be effectively integrated into the SDLC, particularly when using tools like LlamaIndex and Gradio?",
    "user_type": "data_scientist",
    "scenario": "technical"
  },
  {
    "id": "synth_data_scientist_factual_1",
    "question": "What are the best practices for evaluating the performance of LLM applications in real-world data analysis tasks?",
    "user_type": "data_scientist",
    "scenario": "factual"
  },
  {
    "id": "synth_data_scientist_factual_2",
    "question": "How can I effectively use synthetic data to train and improve LLMs for my specific projects?",
    "user_type": "data_scientist",
    "scenario": "factual"
  },
  {
    "id": "synth_ml_engineer_cohort_student_1",
    "question": "What are the best practices for evaluating the performance of LLM applications, and how can I ensure that my implementation meets these standards?",
    "user_type": "ml_engineer",
    "scenario": "cohort_student"
  },
  {
    "id": "synth_ml_engineer_cohort_student_2",
    "question": "Can you explain how to effectively use tools like LlamaIndex and Gradio in the context of prompt engineering and observability for my LLM projects?",
    "user_type": "ml_engineer",
    "scenario": "cohort_student"
  },
  {
    "id": "synth_ml_engineer_general_1",
    "question": "What are the best practices for evaluating the performance of LLM-based applications, particularly in terms of accuracy and user satisfaction?",
    "user_type": "ml_engineer",
    "scenario": "general"
  },
  {
    "id": "synth_ml_engineer_general_2",
    "question": "Can you explain how synthetic data can be effectively used in the development lifecycle of LLM applications, and what are the trade-offs to consider?",
    "user_type": "ml_engineer",
    "scenario": "general"
  },
  {
    "id": "synth_ml_engineer_technical_1",
    "question": "What are the best practices for integrating synthetic data generation into the SDLC when developing LLM applications?",
    "user_type": "ml_engineer",
    "scenario": "technical"
  },
  {
    "id": "synth_ml_engineer_technical_2",
    "question": "How can I effectively evaluate the performance of my LLM-based system in production, specifically in terms of accuracy and reliability?",
    "user_type": "ml_engineer",
    "scenario": "technical"
  },
  {
    "id": "synth_ml_engineer_factual_1",
    "question": "What are the best practices for evaluating LLM performance in real-world applications, and how can we effectively implement these in our SDLC?",
    "user_type": "ml_engineer",
    "scenario": "factual"
  },
  {
    "id": "synth_ml_engineer_factual_2",
    "question": "Can you provide examples of how to utilize synthetic data for training LLMs, particularly in scenarios where real data is limited or sensitive?",
    "user_type": "ml_engineer",
    "scenario": "factual"
  }
]